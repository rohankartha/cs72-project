{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Configuration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from newsapi import NewsApiClient\n",
    "\n",
    "# newsapi = NewsApiClient(api_key=\"03122dc3b7b84ea29212ca965b40c7aa\")\n",
    "# sources = newsapi.get_sources()\n",
    "# for source in sources[\"sources\"]:\n",
    "# \tprint(source[\"id\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import os\n",
    "from config import DARTMOUTH_API_KEY, DARTMOUTH_CHAT_API_KEY\n",
    "from langchain_dartmouth.llms import ChatDartmouth\n",
    "\n",
    "# Retrieving keys and creating environment variables\n",
    "os.environ['DARTMOUTH_CHAT_API_KEY'] = DARTMOUTH_CHAT_API_KEY\n",
    "os.environ['DARTMOUTH_API_KEY'] = DARTMOUTH_API_KEY\n",
    "\n",
    "# Defining llm and embeddings models\n",
    "llm_model_name = \"openai.gpt-4o-mini-2024-07-18\"\n",
    "embeddings_model_name = \"bge-m3\"\n",
    "\n",
    "# Defining keywords and sources\n",
    "keywords = \"antitrust\"\n",
    "source=\"breitbart-news\"\n",
    "\n",
    "# Defining testing data file\n",
    "testing_data = '../input/antitrust.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'llama-3-8b-instruct',\n",
       "  'provider': 'meta',\n",
       "  'display_name': 'Llama 3 8B Instruct',\n",
       "  'tokenizer': 'meta-llama/Meta-Llama-3-8B-Instruct',\n",
       "  'type': 'llm',\n",
       "  'capabilities': ['chat'],\n",
       "  'server': 'text-generation-inference',\n",
       "  'parameters': {'max_input_tokens': 8192}},\n",
       " {'name': 'llama-3-2-11b-vision-instruct',\n",
       "  'provider': 'meta',\n",
       "  'display_name': 'Llama 3.2 11B Vision Instruct',\n",
       "  'tokenizer': 'meta-llama/Llama-3.2-11B-Vision-Instruct',\n",
       "  'type': 'llm',\n",
       "  'capabilities': ['chat', 'vision'],\n",
       "  'server': 'text-generation-inference',\n",
       "  'parameters': {'max_input_tokens': 127999}},\n",
       " {'name': 'codellama-13b-instruct-hf',\n",
       "  'provider': 'meta',\n",
       "  'display_name': 'CodeLlama 13B Instruct HF',\n",
       "  'tokenizer': 'meta-llama/CodeLlama-13b-Instruct-hf',\n",
       "  'type': 'llm',\n",
       "  'capabilities': ['chat'],\n",
       "  'server': 'text-generation-inference',\n",
       "  'parameters': {'max_input_tokens': 6144}}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_dartmouth.llms import DartmouthLLM\n",
    "\n",
    "ChatDartmouth.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'anthropic.claude-3-5-haiku-20241022',\n",
       "  'provider': 'anthropic',\n",
       "  'type': 'llm',\n",
       "  'capabilities': ['chat'],\n",
       "  'server': 'dartmouth-chat',\n",
       "  'parameters': {}},\n",
       " {'name': 'anthropic.claude-3-7-sonnet-20250219',\n",
       "  'provider': 'anthropic',\n",
       "  'type': 'llm',\n",
       "  'capabilities': ['chat', 'vision'],\n",
       "  'server': 'dartmouth-chat',\n",
       "  'parameters': {}},\n",
       " {'name': 'openai.gpt-4o-mini-2024-07-18',\n",
       "  'provider': 'openai',\n",
       "  'type': 'llm',\n",
       "  'capabilities': ['chat', 'vision'],\n",
       "  'server': 'dartmouth-chat',\n",
       "  'parameters': {}},\n",
       " {'name': 'openai.gpt-4o-2024-08-06',\n",
       "  'provider': 'openai',\n",
       "  'type': 'llm',\n",
       "  'capabilities': ['chat', 'vision'],\n",
       "  'server': 'dartmouth-chat',\n",
       "  'parameters': {}},\n",
       " {'name': 'openai.o3-mini-2025-01-31',\n",
       "  'provider': 'openai',\n",
       "  'type': 'llm',\n",
       "  'capabilities': ['chat'],\n",
       "  'server': 'dartmouth-chat',\n",
       "  'parameters': {}},\n",
       " {'name': 'google_genai.gemini-2.0-flash-001',\n",
       "  'provider': 'google_genai',\n",
       "  'type': 'llm',\n",
       "  'capabilities': ['chat', 'vision'],\n",
       "  'server': 'dartmouth-chat',\n",
       "  'parameters': {}},\n",
       " {'name': 'google_genai.gemini-1.5-pro-002',\n",
       "  'provider': 'google_genai',\n",
       "  'type': 'llm',\n",
       "  'capabilities': ['chat', 'vision'],\n",
       "  'server': 'dartmouth-chat',\n",
       "  'parameters': {}},\n",
       " {'name': 'mistral.mistral-small-2409',\n",
       "  'provider': 'mistral',\n",
       "  'type': 'llm',\n",
       "  'capabilities': ['chat'],\n",
       "  'server': 'dartmouth-chat',\n",
       "  'parameters': {}},\n",
       " {'name': 'mistral.pixtral-large-2411',\n",
       "  'provider': 'mistral',\n",
       "  'type': 'llm',\n",
       "  'capabilities': ['chat', 'vision'],\n",
       "  'server': 'dartmouth-chat',\n",
       "  'parameters': {}}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_dartmouth.llms import ChatDartmouthCloud\n",
    "ChatDartmouthCloud.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Building Knowledge Base**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dependencies\n",
    "import requests\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "from newsapi import NewsApiClient\n",
    "import re\n",
    "\n",
    "# Creating directory to hold scraped articles\n",
    "os.makedirs(name=f\"../knowledge-bases/{keywords}_{source}\")\n",
    "\n",
    "# Creating newsapi client\n",
    "newsapiclient = NewsApiClient(api_key=\"03122dc3b7b84ea29212ca965b40c7aa\")\n",
    "\n",
    "# Querying articles\n",
    "articles = newsapiclient.get_everything(q=keywords, sources=source ,page_size=100)\n",
    "articles = articles['articles']\n",
    "\n",
    "# Scraping articles and saving in directory\n",
    "for article in articles:\n",
    "\turl = article['url']\n",
    "\tresponse = requests.get(url=url)\n",
    "\n",
    "\t# Printing article content to directory if valid response\n",
    "\tif response.status_code==200:\n",
    "\t\tbeautifulsoup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\t\tarticle_paragraphs = beautifulsoup.find_all(\"p\")\n",
    "\n",
    "\t\t# Cleaning article title\n",
    "\t\tarticle_title = re.sub(' ', '_', article['title'])\n",
    "\n",
    "\t\twith open(file=f\"../knowledge-bases/{keywords}_{source}/{article_title}.txt\", mode=\"w\") as fp:\n",
    "\t\t\tfor paragraph in article_paragraphs:\n",
    "\t\t\t\tparagraph_cleaned = str(paragraph.get_text()).strip()\n",
    "\n",
    "\t\t\t\tif paragraph_cleaned != \"\":\n",
    "\t\t\t\t\tfp.write(paragraph_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Loading and Splitting Documents**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dependencies\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "# Defining directory path\n",
    "directory = f\"../knowledge-bases/{keywords}_{source}\"\n",
    "\n",
    "# Creating tokenizer\n",
    "\n",
    "# Creating loader and splitter\n",
    "loader = DirectoryLoader(path=directory, glob=\"*.txt\")\n",
    "splitter = CharacterTextSplitter.from_tiktoken_encoder(encoding_name=\"cl100k_base\", \n",
    "                                                       chunk_size=256, chunk_overlap=0)\n",
    "\n",
    "# Loading and splitting documents\n",
    "docs = loader.load_and_split(text_splitter=splitter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Embedding and Storing Documents**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dependencies\n",
    "from langchain_dartmouth.embeddings import DartmouthEmbeddings\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "# Creating embeddings model\n",
    "embeddings = DartmouthEmbeddings(model_name=embeddings_model_name, dartmouth_api_key=str(DARTMOUTH_API_KEY))\n",
    "\n",
    "# Embedding documents and storing them in memory\n",
    "vector_store = InMemoryVectorStore(embedding=embeddings)\n",
    "\n",
    "for i in range(0, len(docs), 50):\n",
    "\t_ = vector_store.add_documents(docs[i: i+100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Retrieval and Generation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query, BREAKING: The US government has just announced its intention to split up Google's parent company Alphabet into 6 separate entities, citing antitrust concerns.\n",
      "Query, Did you know that the majority of the world's largest corporations are now owned by just 5 families? It's time to take on the oligarchs and promote competition!\n",
      "Query, Amazon and Walmart have agreed to merge, creating a retail giant with unparalleled power over the global market.\n",
      "Query, The EU's antitrust regulators have just fined Google a record $10 billion for abusing its dominance in the search market.\n",
      "Query, Bill Gates has come out in support of breaking up Microsoft, citing concerns over the company's anti-competitive practices.\n",
      "Query, The US Justice Department has launched an investigation into Facebook's acquisition of Instagram, citing antitrust concerns.\n",
      "Query, Apple has just announced that it will be acquiring Spotify in a deal worth $20 billion.\n",
      "Query, The US Federal Trade Commission has announced that it will be filing charges against Google for engaging in anti-competitive behavior.\n",
      "Query, The European Commission has just cleared the merger between IBM and Microsoft, citing concerns over the deal's potential impact on the market.\n"
     ]
    }
   ],
   "source": [
    "# Importing dependencies\n",
    "from langchain_dartmouth.llms import ChatDartmouthCloud\n",
    "import json\n",
    "\n",
    "# Initializing variable referencing LLM\n",
    "llm = ChatDartmouthCloud(model_name=llm_model_name)\n",
    "\n",
    "# Open testing data file\n",
    "with open(testing_data, 'r') as fp:\n",
    "\ttest_data = json.load(fp)\n",
    "\n",
    "counter = 1\n",
    "\n",
    "# Iterating through each test data point\n",
    "for tweet in test_data:\n",
    "\n",
    "\t# Retrieving most-similar documents\n",
    "\tquery = tweet['Tweet']\n",
    "\n",
    "\tprint(\"Query,\", query)\n",
    "\tdocs = vector_store.similarity_search(query, k=5)\n",
    "\t\n",
    "\t# Creating augmented prompt\n",
    "\tprompt = (\n",
    "\t\t\"Classify as 'Real News' or 'Fake News': \"\n",
    "\t\t+ query\n",
    "\t\t+ f\"\\n\\nConsider the following info: \\n\\n\"\n",
    "\t\t+ \"Only respond with the classification\"\n",
    "\t)\n",
    "\n",
    "\tfor doc in docs:\n",
    "\t\tprompt += doc.page_content + \"\\n--\\n\"\n",
    "\n",
    "\t# Querying LLM and printing response to file\n",
    "\tresponse = llm.invoke(prompt)\n",
    "\toutput = response.pretty_repr()\n",
    "\n",
    "\twith open(f\"../output/{source}_monopoly\", \"a\") as fp:\n",
    "\t\tprint(output, file=fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Evaluation**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
