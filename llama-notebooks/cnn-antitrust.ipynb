{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Llama w/ Augmentation** ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abc-news\n",
      "abc-news-au\n",
      "aftenposten\n",
      "al-jazeera-english\n",
      "ansa\n",
      "argaam\n",
      "ars-technica\n",
      "ary-news\n",
      "associated-press\n",
      "australian-financial-review\n",
      "axios\n",
      "bbc-news\n",
      "bbc-sport\n",
      "bild\n",
      "blasting-news-br\n",
      "bleacher-report\n",
      "bloomberg\n",
      "breitbart-news\n",
      "business-insider\n",
      "buzzfeed\n",
      "cbc-news\n",
      "cbs-news\n",
      "cnn\n",
      "cnn-es\n",
      "crypto-coins-news\n",
      "der-tagesspiegel\n",
      "die-zeit\n",
      "el-mundo\n",
      "engadget\n",
      "entertainment-weekly\n",
      "espn\n",
      "espn-cric-info\n",
      "financial-post\n",
      "focus\n",
      "football-italia\n",
      "fortune\n",
      "four-four-two\n",
      "fox-news\n",
      "fox-sports\n",
      "globo\n",
      "google-news\n",
      "google-news-ar\n",
      "google-news-au\n",
      "google-news-br\n",
      "google-news-ca\n",
      "google-news-fr\n",
      "google-news-in\n",
      "google-news-is\n",
      "google-news-it\n",
      "google-news-ru\n",
      "google-news-sa\n",
      "google-news-uk\n",
      "goteborgs-posten\n",
      "gruenderszene\n",
      "hacker-news\n",
      "handelsblatt\n",
      "ign\n",
      "il-sole-24-ore\n",
      "independent\n",
      "infobae\n",
      "info-money\n",
      "la-gaceta\n",
      "la-nacion\n",
      "la-repubblica\n",
      "le-monde\n",
      "lenta\n",
      "lequipe\n",
      "les-echos\n",
      "liberation\n",
      "marca\n",
      "mashable\n",
      "medical-news-today\n",
      "msnbc\n",
      "mtv-news\n",
      "mtv-news-uk\n",
      "national-geographic\n",
      "national-review\n",
      "nbc-news\n",
      "news24\n",
      "new-scientist\n",
      "news-com-au\n",
      "newsweek\n",
      "new-york-magazine\n",
      "next-big-future\n",
      "nfl-news\n",
      "nhl-news\n",
      "nrk\n",
      "politico\n",
      "polygon\n",
      "rbc\n",
      "recode\n",
      "reddit-r-all\n",
      "reuters\n",
      "rt\n",
      "rte\n",
      "rtl-nieuws\n",
      "sabq\n",
      "spiegel-online\n",
      "svenska-dagbladet\n",
      "t3n\n",
      "talksport\n",
      "techcrunch\n",
      "techcrunch-cn\n",
      "techradar\n",
      "the-american-conservative\n",
      "the-globe-and-mail\n",
      "the-hill\n",
      "the-hindu\n",
      "the-huffington-post\n",
      "the-irish-times\n",
      "the-jerusalem-post\n",
      "the-lad-bible\n",
      "the-next-web\n",
      "the-sport-bible\n",
      "the-times-of-india\n",
      "the-verge\n",
      "the-wall-street-journal\n",
      "the-washington-post\n",
      "the-washington-times\n",
      "time\n",
      "usa-today\n",
      "vice-news\n",
      "wired\n",
      "wired-de\n",
      "wirtschafts-woche\n",
      "xinhua-net\n",
      "ynet\n"
     ]
    }
   ],
   "source": [
    "newsapi = NewsApiClient(api_key=\"03122dc3b7b84ea29212ca965b40c7aa\")\n",
    "sources = newsapi.get_sources()\n",
    "for source in sources[\"sources\"]:\n",
    "\tprint(source[\"id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import os\n",
    "from config import DARTMOUTH_API_KEY, DARTMOUTH_CHAT_API_KEY\n",
    "from langchain_dartmouth.llms import DartmouthLLM\n",
    "\n",
    "# Retrieving keys and creating environment variables\n",
    "os.environ['DARTMOUTH_CHAT_API_KEY'] = DARTMOUTH_CHAT_API_KEY\n",
    "os.environ['DARTMOUTH_API_KEY'] = DARTMOUTH_API_KEY\n",
    "\n",
    "# Defining llm and embeddings models\n",
    "llm_model_name = \"llama-3-8b-instruct\"\n",
    "embeddings_model_name = \"bge-m3\"\n",
    "\n",
    "# Defining keywords and sources\n",
    "keywords = \"antitrust OR Lina Khan OR monopoly OR regulation\"\n",
    "source=\"cnn\"\n",
    "\n",
    "# Defining testing data file\n",
    "testing_data = '../input/antitrust.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building Knowledge Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dependencies\n",
    "import requests\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "from newsapi import NewsApiClient\n",
    "import re\n",
    "\n",
    "# Creating directory to hold scraped articles\n",
    "os.makedirs(name=f\"../knowledge-bases/{keywords}_{source}\")\n",
    "\n",
    "# Creating newsapi client\n",
    "newsapiclient = NewsApiClient(api_key=\"03122dc3b7b84ea29212ca965b40c7aa\")\n",
    "\n",
    "# Querying articles\n",
    "articles = newsapiclient.get_everything(q=keywords, sources=source ,page_size=100)\n",
    "articles = articles['articles']\n",
    "\n",
    "# Scraping articles and saving in directory\n",
    "for article in articles:\n",
    "\turl = article['url']\n",
    "\tresponse = requests.get(url=url)\n",
    "\n",
    "\t# Printing article content to directory if valid response\n",
    "\tif response.status_code==200:\n",
    "\t\tbeautifulsoup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\t\tarticle_paragraphs = beautifulsoup.find_all(\"p\")\n",
    "\n",
    "\t\t# Cleaning article title\n",
    "\t\tarticle_title = re.sub(' ', '_', article['title'])\n",
    "\n",
    "\t\twith open(file=f\"../knowledge-bases/{keywords}_{source}/{article_title}.txt\", mode=\"w\") as fp:\n",
    "\t\t\tfor paragraph in article_paragraphs:\n",
    "\t\t\t\tparagraph_cleaned = str(paragraph.get_text()).strip()\n",
    "\n",
    "\t\t\t\tif paragraph_cleaned != \"\":\n",
    "\t\t\t\t\tfp.write(paragraph_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading and Splitting Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 508, which is longer than the specified 256\n",
      "Created a chunk of size 414, which is longer than the specified 256\n",
      "Created a chunk of size 337, which is longer than the specified 256\n",
      "Created a chunk of size 775, which is longer than the specified 256\n",
      "Created a chunk of size 447, which is longer than the specified 256\n",
      "Created a chunk of size 475, which is longer than the specified 256\n",
      "Created a chunk of size 1214, which is longer than the specified 256\n",
      "Created a chunk of size 529, which is longer than the specified 256\n",
      "Created a chunk of size 279, which is longer than the specified 256\n",
      "Created a chunk of size 306, which is longer than the specified 256\n",
      "Created a chunk of size 513, which is longer than the specified 256\n",
      "Created a chunk of size 1099, which is longer than the specified 256\n",
      "Created a chunk of size 352, which is longer than the specified 256\n",
      "Created a chunk of size 433, which is longer than the specified 256\n",
      "Created a chunk of size 883, which is longer than the specified 256\n",
      "Created a chunk of size 1277, which is longer than the specified 256\n",
      "Created a chunk of size 427, which is longer than the specified 256\n",
      "Created a chunk of size 586, which is longer than the specified 256\n",
      "Created a chunk of size 290, which is longer than the specified 256\n",
      "Created a chunk of size 351, which is longer than the specified 256\n",
      "Created a chunk of size 410, which is longer than the specified 256\n",
      "Created a chunk of size 325, which is longer than the specified 256\n",
      "Created a chunk of size 468, which is longer than the specified 256\n",
      "Created a chunk of size 722, which is longer than the specified 256\n",
      "Created a chunk of size 521, which is longer than the specified 256\n",
      "Created a chunk of size 915, which is longer than the specified 256\n",
      "Created a chunk of size 607, which is longer than the specified 256\n",
      "Created a chunk of size 492, which is longer than the specified 256\n",
      "Created a chunk of size 286, which is longer than the specified 256\n"
     ]
    }
   ],
   "source": [
    "# Importing dependencies\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "# Defining directory path\n",
    "directory = f\"../knowledge-bases/{keywords}_{source}\"\n",
    "\n",
    "# Creating tokenizer\n",
    "\n",
    "# Creating loader and splitter\n",
    "loader = DirectoryLoader(path=directory, glob=\"*.txt\")\n",
    "splitter = CharacterTextSplitter.from_tiktoken_encoder(encoding_name=\"cl100k_base\", \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t   chunk_size=256, chunk_overlap=0)\n",
    "\n",
    "# Loading and splitting documents\n",
    "docs = loader.load_and_split(text_splitter=splitter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embedding and Storing Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dependencies\n",
    "from langchain_dartmouth.embeddings import DartmouthEmbeddings\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "# Creating embeddings model\n",
    "embeddings = DartmouthEmbeddings(model_name=embeddings_model_name, dartmouth_api_key=str(DARTMOUTH_API_KEY))\n",
    "\n",
    "# Embedding documents and storing them in memory\n",
    "vector_store = InMemoryVectorStore(embedding=embeddings)\n",
    "\n",
    "for i in range(0, len(docs), 50):\n",
    "\t_ = vector_store.add_documents(docs[i: i+100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieval and Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dependencies\n",
    "from langchain_dartmouth.llms import ChatDartmouth\n",
    "import json\n",
    "\n",
    "# Initializing variable to hold output\n",
    "output = \"\"\n",
    "\n",
    "# Initializing variable referencing LLM\n",
    "llm = ChatDartmouth(model_name=\"llama-3-1-8b-instruct\")\n",
    "\n",
    "# Open testing data file\n",
    "with open(testing_data, 'r') as fp:\n",
    "\ttest_data = json.load(fp)\n",
    "\n",
    "# Iterating through each test data point\n",
    "for tweet in test_data:\n",
    "\n",
    "\t# Retrieving most-similar documents\n",
    "\tquery = tweet['Tweet']\n",
    "\tdocs = vector_store.similarity_search(query, k=5)\n",
    "\t\n",
    "\t# Creating augmented prompt\n",
    "\tprompt = (\n",
    "\t\t\"Classify tweet as 'Real News' or 'Fake News': \"\n",
    "\t\t+ query\n",
    "\t\t+ f\"\\n\\nConsider the following info: \\n\\n\"\n",
    "\t)\n",
    "\n",
    "\tfor doc in docs:\n",
    "\t\tprompt += doc.page_content + \"\\n--\\n\"\n",
    "\t\n",
    "\tprompt = prompt + \"Only respond with the classification.\"\n",
    "\n",
    "\t# Querying LLM and printing response to file\n",
    "\tresponse = llm.invoke(prompt)\n",
    "\toutput = response.pretty_repr() + output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall:  0.8076923076923077\n",
      "Precision:  0.525\n",
      "Accuracy:  0.5\n",
      "F1 Score 0.6363636363636364\n",
      "Confusion matrix:  [[ 3 19]\n",
      " [ 5 21]]\n"
     ]
    }
   ],
   "source": [
    "# Importing dependencies\n",
    "import json\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, confusion_matrix, f1_score\n",
    "import io\n",
    "\n",
    "# Loading true labels\n",
    "with open(testing_data) as fp_input:\n",
    "\tinput_data = json.load(fp_input)\n",
    "\n",
    "\t# Encoding true labels as 0s and 1s\n",
    "\ty_actual = []\n",
    "\n",
    "\tfor entry in input_data:\n",
    "\t\tlabel = entry['Label']\n",
    "\n",
    "\t\tif label == \"Real News\":\n",
    "\t\t\ty_actual.append(1)\n",
    "\t\telif label == \"Fake News\":\n",
    "\t\t\ty_actual.append(0)\n",
    "\n",
    "# Extracting predicted labels\n",
    "y_pred = []\n",
    "\n",
    "# Encoding true labels as 0s and 1s\n",
    "with io.StringIO(output) as fp_output:\n",
    "\n",
    "\tfor line in fp_output:\n",
    "\t\tif \"Real News\" in line:\n",
    "\t\t\ty_pred.append(1)\n",
    "\t\telif \"Fake News\" in line:\n",
    "\t\t\ty_pred.append(0)\n",
    "\n",
    "# Calculating and printing metrics\n",
    "recall = recall_score(y_true=y_actual, y_pred=y_pred)\n",
    "precision = precision_score(y_true=y_actual, y_pred=y_pred)\n",
    "accuracy = accuracy_score(y_true=y_actual, y_pred=y_pred)\n",
    "f1score = f1_score(y_true=y_actual, y_pred=y_pred)\n",
    "confusion_matrix = confusion_matrix(y_true=y_actual, y_pred=y_pred)\n",
    "\n",
    "print(\"Recall: \", recall)\n",
    "print(\"Precision: \",precision)\n",
    "print(\"Accuracy: \",accuracy)\n",
    "print(\"F1 Score\", f1score)\n",
    "print(\"Confusion matrix: \",confusion_matrix)\n",
    "\t\t\n",
    "\t\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Llama w/o Augmentation** ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dependencies\n",
    "import json\n",
    "\n",
    "# Initializing variable to hold output\n",
    "output = \"\"\n",
    "\n",
    "# Initializing variable referencing LLM\n",
    "llm = ChatDartmouth(model_name=\"llama-3-1-8b-instruct\")\n",
    "\n",
    "# Open testing data file\n",
    "with open(testing_data, 'r') as fp:\n",
    "\ttest_data = json.load(fp)\n",
    "\n",
    "# Iterating through each test data point\n",
    "for tweet in test_data:\n",
    "\n",
    "\t# Creating non-augmented prompt\n",
    "\tquery = tweet['Tweet']\n",
    "\tprompt = (\n",
    "\t\t\"Classify this tweet as 'Real News' or 'Fake News': \"\n",
    "\t\t+ query\n",
    "\t\t+ \"Only respond with the classification.\"\n",
    "\t)\n",
    "\n",
    "\t# Querying LLM and printing response to file\n",
    "\tresponse = llm.invoke(prompt)\n",
    "\toutput = response.pretty_repr() + output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall:  0.5384615384615384\n",
      "Precision:  0.4827586206896552\n",
      "Accuracy:  0.4375\n",
      "F1 Score 0.509090909090909\n",
      "Confusion matrix:  [[ 7 15]\n",
      " [12 14]]\n"
     ]
    }
   ],
   "source": [
    "# Importing dependencies\n",
    "import json\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, confusion_matrix, f1_score\n",
    "import io\n",
    "\n",
    "# Loading true labels\n",
    "with open(testing_data) as fp_input:\n",
    "\tinput_data = json.load(fp_input)\n",
    "\n",
    "\t# Encoding true labels as 0s and 1s\n",
    "\ty_actual = []\n",
    "\n",
    "\tfor entry in input_data:\n",
    "\t\tlabel = entry['Label']\n",
    "\n",
    "\t\tif label == \"Real News\":\n",
    "\t\t\ty_actual.append(1)\n",
    "\t\telif label == \"Fake News\":\n",
    "\t\t\ty_actual.append(0)\n",
    "\n",
    "# Extracting predicted labels\n",
    "y_pred = []\n",
    "\n",
    "# Encoding true labels as 0s and 1s\n",
    "with io.StringIO(output) as fp_output:\n",
    "\n",
    "\tfor line in fp_output:\n",
    "\t\tif \"Real News\" in line:\n",
    "\t\t\ty_pred.append(1)\n",
    "\t\telif \"Fake News\" in line:\n",
    "\t\t\ty_pred.append(0)\n",
    "\n",
    "# Calculating and printing metrics\n",
    "recall = recall_score(y_true=y_actual, y_pred=y_pred)\n",
    "precision = precision_score(y_true=y_actual, y_pred=y_pred)\n",
    "accuracy = accuracy_score(y_true=y_actual, y_pred=y_pred)\n",
    "f1score = f1_score(y_true=y_actual, y_pred=y_pred)\n",
    "confusion_matrix = confusion_matrix(y_true=y_actual, y_pred=y_pred)\n",
    "\n",
    "print(\"Recall: \", recall)\n",
    "print(\"Precision: \",precision)\n",
    "print(\"Accuracy: \",accuracy)\n",
    "print(\"F1 Score\", f1score)\n",
    "print(\"Confusion matrix: \",confusion_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
