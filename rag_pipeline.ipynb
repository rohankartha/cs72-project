{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Configuration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import os\n",
    "from config import DARTMOUTH_API_KEY, DARTMOUTH_CHAT_API_KEY\n",
    "from langchain_dartmouth.llms import ChatDartmouth\n",
    "\n",
    "# Retrieving keys and creating environment variables\n",
    "os.environ['DARTMOUTH_CHAT_API_KEY'] = DARTMOUTH_CHAT_API_KEY\n",
    "os.environ['DARTMOUTH_API_KEY'] = DARTMOUTH_API_KEY\n",
    "\n",
    "# Defining llm and embeddings models\n",
    "llm_model_name = \"openai.gpt-4o-mini-2024-07-18\"\n",
    "embeddings_model_name = \"bge-large-en-v1-5\"\n",
    "\n",
    "# Defining keywords and sources\n",
    "keywords = \"Trump\"\n",
    "source=\"cnn\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Building Knowledge Base**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dependencies\n",
    "import requests\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "from newsapi import NewsApiClient\n",
    "import re\n",
    "\n",
    "# Creating directory to hold scraped articles\n",
    "os.makedirs(name=f\"{keywords}_{source}\")\n",
    "\n",
    "# Creating newsapi client\n",
    "newsapiclient = NewsApiClient(api_key=\"03122dc3b7b84ea29212ca965b40c7aa\")\n",
    "\n",
    "# Querying articles\n",
    "articles = newsapiclient.get_everything(q=keywords, sources=source ,page_size=1)\n",
    "articles = articles['articles']\n",
    "\n",
    "# Scraping articles and saving in directory\n",
    "for article in articles:\n",
    "\turl = article['url']\n",
    "\tresponse = requests.get(url=url)\n",
    "\n",
    "\t# Printing article content to directory if valid response\n",
    "\tif response.status_code==200:\n",
    "\t\tbeautifulsoup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\t\tarticle_paragraphs = beautifulsoup.find_all(\"p\")\n",
    "\n",
    "\t\t# Cleaning article title\n",
    "\t\tarticle_title = re.sub(' ', '_', article['title'])\n",
    "\n",
    "\t\twith open(file=f\"{keywords}_{source}/{article_title}.txt\", mode=\"w\") as fp:\n",
    "\t\t\tfor paragraph in article_paragraphs:\n",
    "\t\t\t\tfp.write(str(paragraph.get_text()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Loading and Splitting Documents**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n"
     ]
    }
   ],
   "source": [
    "# Importing dependencies\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "# Defining directory path\n",
    "directory = f\"{keywords}_{source}\"\n",
    "\n",
    "# Creating loader and splitter\n",
    "loader = DirectoryLoader(path=directory, glob=\"*.txt\")\n",
    "splitter = CharacterTextSplitter.from_tiktoken_encoder(encoding_name=\"cl100k_base\", \n",
    "                                                       chunk_size=256, chunk_overlap=0)\n",
    "\n",
    "# Loading and splitting documents\n",
    "docs = loader.load_and_split(text_splitter=splitter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Embedding and Storing Documents**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5ce81580-4752-4ae9-b6bd-108415723856',\n",
       " 'a19e3f5c-2691-402c-b53f-b1bf88cb52ab',\n",
       " 'f578be28-b3e1-48cf-be57-a8c80359024a',\n",
       " '732260b6-1bc1-420f-8045-381351a00b59']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing dependencies\n",
    "from langchain_dartmouth.embeddings import DartmouthEmbeddings\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "# Creating embeddings model\n",
    "embeddings = DartmouthEmbeddings(model_name=embeddings_model_name, dartmouth_api_key=str(DARTMOUTH_API_KEY))\n",
    "\n",
    "# Embedding documents and storing them in memory\n",
    "vector_store = InMemoryVectorStore(embedding=embeddings)\n",
    "_ = vector_store.add_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Retrieval**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Is Trump good for climate?\"\n",
    "\n",
    "docs = vector_store.similarity_search(query, k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Generation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Based on the provided context, the Trump administration's actions, particularly the significant layoffs at the National Oceanic and Atmospheric Administration (NOAA), suggest a negative impact on climate-related research and forecasting. The termination of around 800 employees, including those involved in weather, climate, and environmental science, raises concerns about the government's commitment to climate science and monitoring. \n",
      "\n",
      "The cuts to staffing in critical areas of weather and climate prediction could undermine the ability to forecast severe weather events and understand climate trends, potentially placing public safety at risk. Therefore, it can be argued that Trump's policies and decisions, as reflected in the context, are not favorable for climate science and environmental monitoring.\n"
     ]
    }
   ],
   "source": [
    "# Importing dependencies\n",
    "from langchain_dartmouth.llms import ChatDartmouthCloud\n",
    "\n",
    "# Initializing variable referencing LLM\n",
    "llm = ChatDartmouthCloud(model_name=llm_model_name)\n",
    "\n",
    "# Creating augmented prompt\n",
    "prompt = (\n",
    "    \"Answer the following query: \"\n",
    "    + query\n",
    "    + \"\\n\\nBase your response on the following context: \\n\\n\"\n",
    ")\n",
    "\n",
    "for doc in docs:\n",
    "    prompt += doc.page_content + \"\\n--\\n\"\n",
    "\n",
    "# Querying LLM and printing response\n",
    "response = llm.invoke(prompt)\n",
    "response.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Evaluation**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
